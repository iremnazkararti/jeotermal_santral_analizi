import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import gdown  # Google Drive'dan veri indirmek iÃ§in
import streamlit as st
import pandas as pd
import gdown  # Google Drive'dan veri indirmek iÃ§in
from sklearn.model_selection import train_test_split
import xgboost as xgb


# ðŸ“Œ Dashboard AyarlarÄ±
st.set_page_config(page_title="âš¡ Enerji Ãœretim Dashboard", layout="wide")

@st.cache_data
def load_data():
    file_id = "1ERlscTm0SV49syHXzyMEvW6pvpPVD3qK"  # Yeni Google Drive ID'si
    url = f"https://drive.google.com/uc?export=download&id={file_id}"  # Yeni indirme linki
    output = "dataset.csv"
    
    try:
        # Veriyi indir
        gdown.download(url, output, quiet=False)
        
        # CSV'yi oku ve iÅŸle
        df = pd.read_csv(output)
        df.rename(columns={"Unnamed: 0": "date"}, inplace=True)
        df["date"] = pd.to_datetime(df["date"])
        df.set_index("date", inplace=True)
        df = df.resample("D").mean().interpolate()  # Eksik verileri doldur
        return df
    
    except Exception as e:
        st.error(f"ðŸ“› Veri yÃ¼klenirken hata oluÅŸtu: {e}")
        return pd.DataFrame()  # Hata durumunda boÅŸ dataframe dÃ¶ndÃ¼r


df = load_data()  # Veriyi yÃ¼kle

# ðŸ“Œ **Sidebar Filtreleri**
st.sidebar.header("âš™ï¸ Filtreler")
start_date = st.sidebar.date_input("BaÅŸlangÄ±Ã§ Tarihi", df.index.min().date())
end_date = st.sidebar.date_input("BitiÅŸ Tarihi", df.index.max().date())
df = df.loc[start_date:end_date]

view_option = st.sidebar.radio(
    "ðŸ” Dashboard SeÃ§:", 
    ["ðŸ“‚ Veri Seti", "ðŸ“Š Zaman Serisi", "ðŸ“‰ Korelasyon", "ðŸ”® Tahminler", "ðŸš¨ Anomali Tespiti"]
)

# ðŸ“‚ **1ï¸âƒ£ Veri Seti**
if view_option == "ðŸ“‚ Veri Seti":
    st.subheader("ðŸ“‚ Veri Seti")
    st.dataframe(df.head(50))
    st.write("SeÃ§ilen tarih aralÄ±ÄŸÄ±nda veri setinden ilk 50 satÄ±r.")

    # KPI KartlarÄ±
    col1, col2 = st.columns(2)
    col1.metric("ðŸ”¹ Ortalama Sinem Ãœretimi (MW)", round(df["sinem_guc_net"].mean(), 2))
    col2.metric("ðŸ”¹ Ortalama Deniz Ãœretimi (MW)", round(df["deniz_guc_net"].mean(), 2))

# ðŸ“Š **2ï¸âƒ£ Zaman Serisi Analizi**
elif view_option == "ðŸ“Š Zaman Serisi":
    st.subheader("ðŸ“Š Enerji Ãœretimi Zaman Serisi")
    fig = px.line(df, x=df.index, y=["sinem_guc_net", "deniz_guc_net"], title="Sinem & Deniz GÃ¼Ã§ Ãœretimi")
    st.plotly_chart(fig, use_container_width=True)

    # Hareketli Ortalama
    df["sinem_7gÃ¼n"] = df["sinem_guc_net"].rolling(7).mean()
    df["deniz_7gÃ¼n"] = df["deniz_guc_net"].rolling(7).mean()
    fig2 = px.line(df, x=df.index, y=["sinem_7gÃ¼n", "deniz_7gÃ¼n"], title="7 GÃ¼nlÃ¼k Hareketli Ortalama")
    st.plotly_chart(fig2, use_container_width=True)

# ðŸ“‰ **3ï¸âƒ£ Korelasyon Analizi**
elif view_option == "ðŸ“‰ Korelasyon":
    st.subheader("ðŸ“‰ Korelasyon Analizi")
    
    # Korelasyon matrisi
    corr = df.corr()

    # Plotly heatmap oluÅŸturma
    fig = px.imshow(
        corr.values,
        x=corr.columns,
        y=corr.index,
        color_continuous_scale="RdBu",  # Alternatif: "Viridis", "Blues"
        title="Korelasyon Matrisi",
        labels=dict(color="Korelasyon"),
        zmin=-1, zmax=1
    )

    # Grafik boyutunu artÄ±r
    fig.update_layout(
        autosize=False,
        width=900,  # GeniÅŸlik (px)
        height=800,  # YÃ¼kseklik (px)
        margin=dict(l=100, r=100, t=100, b=100)
    )

    # GrafiÄŸi gÃ¶ster
    st.plotly_chart(fig, use_container_width=True)


# ðŸ“‰ **5ï¸âƒ£ Tahminleme (Forecasting)**
elif view_option == "ðŸ”® Tahminler":
    st.subheader("ðŸ”® Enerji UÌˆretim Tahminleri")
    model_option = st.selectbox("Tahmin Modeli:", ["XGBoost"])
    days = st.slider("KaÃ§ GÃ¼nlÃ¼k Tahmin YapÄ±lsÄ±n?", 30, 365, 100)

    if st.button("ðŸ“ˆ Tahmini BaÅŸlat"):
        with st.spinner("Tahmin yapÄ±lÄ±yor..."):
            df_daily = df.resample("D").mean()
            forecast_sinem, forecast_deniz = None, None

     
            if model_option == "XGBoost":
                df_xgb = df_daily.copy()
                for lag in range(1, 8):
                    df_xgb[f"sinem_guc_net_lag{lag}"] = df_xgb["sinem_guc_net"].shift(lag)
                    df_xgb[f"deniz_guc_net_lag{lag}"] = df_xgb["deniz_guc_net"].shift(lag)
                df_xgb.dropna(inplace=True)
                features = [col for col in df_xgb.columns if "lag" in col]
                X_train, X_test, y_train_sinem, y_test_sinem = train_test_split(df_xgb[features], df_xgb["sinem_guc_net"], test_size=0.2, shuffle=False)
                X_train, X_test, y_train_deniz, y_test_deniz = train_test_split(df_xgb[features], df_xgb["deniz_guc_net"], test_size=0.2, shuffle=False)
                xgb_model_sinem, xgb_model_deniz = xgb.XGBRegressor(n_estimators=100), xgb.XGBRegressor(n_estimators=100)
                xgb_model_sinem.fit(X_train, y_train_sinem)
                xgb_model_deniz.fit(X_train, y_train_deniz)
                forecast_sinem = xgb_model_sinem.predict(df_xgb[features].iloc[-days:])
                forecast_deniz = xgb_model_deniz.predict(df_xgb[features].iloc[-days:])

            forecast_dates = pd.date_range(df_daily.index[-1] + pd.DateOffset(1), periods=days, freq="D")

            # MAPE Hesaplama Fonksiyonu (Hata Ã–nleme Dahil)
            def mean_absolute_percentage_error(y_true, y_pred):
                y_true = y_true.replace(0, np.nan).dropna()  # 0 olanlarÄ± NaN yap, sonra temizle
                y_pred = y_pred[:len(y_true)]  # Uzunluk eÅŸitle
                if len(y_true) == 0 or len(y_pred) == 0:  # EÄŸer hiÃ§ veri kalmadÄ±ysa NaN dÃ¶ndÃ¼r
                    return np.nan
                return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

            # GerÃ§ek verileri alÄ±rken NaN olanlarÄ± temizle
            last_real_sinem = df_daily["sinem_guc_net"].iloc[-days:].dropna()
            last_real_deniz = df_daily["deniz_guc_net"].iloc[-days:].dropna()

            # MAPE hesaplama
            mape_sinem = mean_absolute_percentage_error(last_real_sinem, forecast_sinem)
            mape_deniz = mean_absolute_percentage_error(last_real_deniz, forecast_deniz)

            # DoÄŸruluk yÃ¼zdesi hesaplama
            accuracy_sinem = 100 - round(mape_sinem, 2) if not np.isnan(mape_sinem) else "Veri Eksik"
            accuracy_deniz = 100 - round(mape_deniz, 2) if not np.isnan(mape_deniz) else "Veri Eksik"

            # Grafik Ã§izimi
            fig = px.line(title="Enerji Ãœretim Tahmini")
            fig.add_scatter(x=df_daily.index, y=df_daily["sinem_guc_net"], mode="lines", name="GerÃ§ek Sinem Ãœretimi", line=dict(color="blue"))
            fig.add_scatter(x=forecast_dates, y=forecast_sinem, mode="lines", name=f"{model_option} Sinem Tahmini", line=dict(color="red"))
            fig.add_scatter(x=df_daily.index, y=df_daily["deniz_guc_net"], mode="lines", name="GerÃ§ek Deniz Ãœretimi", line=dict(color="green"))
            fig.add_scatter(x=forecast_dates, y=forecast_deniz, mode="lines", name=f"{model_option} Deniz Tahmini", line=dict(color="orange"))
            st.plotly_chart(fig, use_container_width=True)

            # DoÄŸruluk oranlarÄ±nÄ± gÃ¶ster
            st.markdown(f"### ðŸŽ¯ Model DoÄŸruluk OranlarÄ±")
            col1, col2 = st.columns(2)
            col1.metric(f"ðŸ”µ {model_option} Sinem Tahmin DoÄŸruluÄŸu", f"% {accuracy_sinem}")
            col2.metric(f"ðŸŸ  {model_option} Deniz Tahmin DoÄŸruluÄŸu", f"% {accuracy_deniz}")


# ðŸš¨ **7ï¸âƒ£ Anomali Tespiti**
elif view_option == "ðŸš¨ Anomali Tespiti":
    st.subheader("ðŸš¨ Anormal Ãœretim DeÄŸerleri")
    threshold = st.slider("Anomali EÅŸik DeÄŸeri", 0.5, 2.0, 1.5)
    anomalies = df[(df["sinem_guc_net"] > threshold * df["sinem_guc_net"].mean())]
    st.dataframe(anomalies)
